Permutation-Invariant Neural Networks and Custom Deep Learning Layers for Data Classification

This project explores the design and implementation of permutation-invariant neural networks, which are tailored to handle structured data where the order of elements does not affect the output. By introducing custom TensorFlow layers, such as BSBPEMultiply for block-wise operations and BSSum for aggregation, the project ensures that the model outputs remain consistent regardless of the input order. These custom layers address a fundamental challenge in machine learning, enabling the development of models for tasks like point cloud classification, social network analysis, and molecular property prediction, where input permutations are common.

To validate the approach, the project utilizes the MNIST dataset as a benchmark. The dataset is preprocessed to introduce random permutations of pixel values, disrupting positional relationships between pixels. The permutation-invariant neural network is then trained to classify these digits based solely on their content, demonstrating the robustness and adaptability of the custom architecture. Performance metrics, including training and validation accuracy and loss, highlight the model's ability to generalize effectively, even with permuted data. This approach showcases how custom layers can enhance neural network performance in scenarios where traditional architectures struggle.

Beyond architecture design, the project incorporates innovative preprocessing and statistical methods, such as histogram-based transformations, to further refine the model. The custom Histogram layer, for example, dynamically analyzes data distributions to improve input preprocessing. These techniques bridge traditional data analysis with modern deep learning, expanding the potential applications of permutation-invariant networks. With its successful integration of advanced neural network design, preprocessing techniques, and robust evaluation, the project lays a solid foundation for future work in creating versatile machine learning models that can adapt to diverse structured data scenarios.

